{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0c8dbe4-dfb4-4649-ac9b-08f4334f64e6",
   "metadata": {},
   "source": [
    "# LeNet Computer Vision Model\n",
    "\n",
    "> https://doi.org/10.1109/5.726791"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88162614",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras.models import Sequential\n",
    "from numpy import ndarray\n",
    "from typing import Any, List\n",
    "from keras import layers, losses\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d831e9",
   "metadata": {},
   "source": [
    "## Download and preparte MNIST dataset\n",
    "\n",
    "1. As the `LeNet` model expects images to be of size *32 x 32*, all images within the *MNIST* dataset need to be scaled from *28 x 28* to *32 x 32*\n",
    "2. As *MNIST* images are in grayscale, we want to binarize them between 0 and 1 (white or black) by dividing their color value by 255\n",
    "3. As *MNIST* images are in grayscale, they do not have the color channel value that is expected by *Keras* `Conv2d` module. In other words, the *MNIST* dataset tensor structure only contains [`batchSize`, `height`, `width`] Thus, we need to add in a fourth dimension to make our tenors look like [`batchSize`, `height`, `width`, `channel`] where `channel` == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22334947",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePadding: List[List[int]] = [[0, 0], [2, 2], [2, 2]]\n",
    "\n",
    "mnist: tuple[tuple[Any, Any]] = load_data()\n",
    "\n",
    "xTrain: ndarray = mnist[0][0]\n",
    "yTrain: ndarray = mnist[0][1]\n",
    "xTest: ndarray = mnist[1][0]\n",
    "yTest: ndarray = mnist[1][1]\n",
    "\n",
    "xTrain = tensorflow.pad(tensor=xTrain, paddings=imagePadding) / 255\n",
    "xTest = tensorflow.pad(tensor=xTest, paddings=imagePadding) / 255\n",
    "\n",
    "xTrain = tensorflow.expand_dims(input=xTrain, axis=3)\n",
    "xTest = tensorflow.expand_dims(input=xTest, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599dd8d2",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "### Architecture\n",
    "\n",
    "[![https://production-media.paperswithcode.com/methods/LeNet_Original_Image_48T74Lc.jpg](https://production-media.paperswithcode.com/methods/LeNet_Original_Image_48T74Lc.jpg)](https://production-media.paperswithcode.com/methods/LeNet_Original_Image_48T74Lc.jpg)\n",
    "\n",
    "> Image from https://production-media.paperswithcode.com/methods/LeNet_Original_Image_48T74Lc.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet: Sequential = Sequential(name=\"LeNet\")\n",
    "lenet.add(layer=layers.Conv2D(filters=6, kernel_size=5, activation=\"tanh\"))\n",
    "lenet.add(layers.AveragePooling2D(pool_size=2))\n",
    "lenet.add(layer=layers.Activation(activation=\"sigmoid\"))\n",
    "lenet.add(layers.Conv2D(16, 5, activation=\"tanh\"))\n",
    "lenet.add(layers.AveragePooling2D(2))\n",
    "lenet.add(layers.Activation(\"sigmoid\"))\n",
    "lenet.add(layers.Conv2D(120, 5, activation=\"tanh\"))\n",
    "lenet.add(layers.Flatten())\n",
    "lenet.add(layers.Dense(84, activation=\"tanh\"))\n",
    "lenet.add(layers.Dense(10, activation=\"softmax\"))\n",
    "lenet.build(input_shape=xTrain.shape)\n",
    "lenet.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=losses.sparse_categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897e0136",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a4ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "logFolder: Path = Path(\"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback: TensorBoard = TensorBoard(\n",
    "    log_dir=logFolder,\n",
    "    histogram_freq=1,\n",
    "    write_images=True,\n",
    ")\n",
    "\n",
    "lenet.fit(\n",
    "    x=xTrain,\n",
    "    y=yTrain,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    callbacks=[tensorboard_callback],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
